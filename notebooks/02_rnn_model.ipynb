{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MusicDataset(Dataset):\n",
    "    def __init__(self, data, seq_length=50):\n",
    "        self.data = data\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        train_seq = self.data[:, index * self.seq_length: (index + 1) * self.seq_length, :]\n",
    "        target_seq = self.data[:, (index + 1) * self.seq_length, :]\n",
    "        return train_seq, target_seq\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(self.data.size(1) / self.seq_length)\n",
    "\n",
    "def grad_clipping(model, theta):\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad[:] *= theta / norm\n",
    "\n",
    "class MusicGenerationRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size=32, n_layers=1):\n",
    "        super(MusicGenerationRNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.gru = nn.GRU(input_size, hidden_size, n_layers)\n",
    "        self.linear = nn.Linear(hidden_size * n_layers, output_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        input = input.permute(0, 2, 1, 3)\n",
    "        input = input.flatten(2, 3)\n",
    "        input = input.permute(1, 0, 2)\n",
    "        _, hidden = self.gru(input, hidden)\n",
    "        h_n = hidden.permute(1, 0, 2)\n",
    "        h_n = h_n.contiguous().flatten(1, 2)\n",
    "        output = self.linear(h_n)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(self.n_layers, batch_size, self.hidden_size).to(device)\n",
    "\n",
    "\n",
    "def train_epoch(dataloader, model, optimizer, criterion):\n",
    "    running_loss = 0\n",
    "    n_obs = 0\n",
    "\n",
    "    for train_seq, target_seq in dataloader:\n",
    "        train_seq = train_seq.to(device)\n",
    "        target_seq = target_seq.to(device)\n",
    "        hidden = model.init_hidden(batch_size=64)\n",
    "        optimizer.zero_grad()\n",
    "        target_seq = target_seq.flatten(1, 2)\n",
    "        output, hidden = model(train_seq, hidden)\n",
    "        loss = criterion(output, target_seq)\n",
    "        loss.backward()\n",
    "        grad_clipping(model, 1)\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        n_obs += train_seq.size()[0]\n",
    "\n",
    "    return running_loss / n_obs * 100\n",
    "\n",
    "\n",
    "def test_epoch(dataloader, model, optimizer, criterion):\n",
    "    running_loss = 0\n",
    "    n_obs = 0\n",
    "\n",
    "    for train_seq, target_seq in dataloader:\n",
    "        train_seq = train_seq.to(device)\n",
    "        target_seq = target_seq.to(device)\n",
    "        hidden = model.init_hidden(batch_size=64)\n",
    "        target_seq = target_seq.flatten(1, 2)\n",
    "        optimizer.zero_grad()\n",
    "        output, hidden = model(train_seq, hidden)\n",
    "        loss = criterion(output, target_seq)\n",
    "        running_loss += loss.item()\n",
    "        n_obs += train_seq.size()[0]\n",
    "\n",
    "    return running_loss / n_obs * 100\n",
    "\n",
    "\n",
    "def fit(model, checkpoint_path, optimizer, scheduler, criterion, train_dataloader, test_dataloader):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        model.train()\n",
    "        train_epoch_loss = train_epoch(train_dataloader, model, optimizer, criterion)\n",
    "        train_losses.append(train_epoch_loss)\n",
    "        scheduler.step()\n",
    "        model.eval()\n",
    "        test_epoch_loss = test_epoch(test_dataloader, model, optimizer, criterion)\n",
    "        test_losses.append(test_epoch_loss)\n",
    "\n",
    "        print('Epoch {}, Train Loss: {}, Test Loss: {}, Time: {}'.format(epoch, train_epoch_loss, test_epoch_loss,\n",
    "                                                                         datetime.now()))\n",
    "\n",
    "    torch.save(model, os.path.join(checkpoint_path, 'model_torch.pt'))\n",
    "\n",
    "    return train_losses, test_losses"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_path = os.path.join('data')\n",
    "preparation_path = os.path.join(input_path, '02_preparation')\n",
    "model_path = os.path.join(input_path, '03_model')\n",
    "checkpoint_path = os.path.join(model_path, 'gan', 'checkpoints')\n",
    "\n",
    "torch_tensor = torch.load(os.path.join(preparation_path, 'tensor.pt'))\n",
    "torch_tensor = torch_tensor.type(torch.float32)\n",
    "\n",
    "train_dataset = MusicDataset(torch_tensor[:, 0:int(torch_tensor.shape[1] * 0.8), :], seq_length=64)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64,\n",
    "                          drop_last=True)\n",
    "\n",
    "test_dataset = MusicDataset(torch_tensor[:, int(torch_tensor.shape[1] * 0.8):, :], seq_length=64)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64,\n",
    "                         drop_last=True)\n",
    "\n",
    "hidden_size = 512\n",
    "n_layers = 3\n",
    "n_epochs = 1\n",
    "lr = 0.001\n",
    "lr_lambda = 0.98\n",
    "\n",
    "model = MusicGenerationRNN(input_size=504, hidden_size=hidden_size, output_size=504, n_layers=n_layers).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: lr_lambda ** epoch)\n",
    "criterion = nn.MSELoss()\n",
    "train_losses, test_losses = fit(model, checkpoint_path, optimizer, scheduler, criterion, train_loader, test_loader)\n",
    "\n",
    "pd.DataFrame(train_losses).to_csv(os.path.join(checkpoint_path, 'train_losses_rnn.csv'), index=False)\n",
    "pd.DataFrame(test_losses).to_csv(os.path.join(checkpoint_path, 'test_losses_rnn.csv'), index=False)\n",
    "\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}